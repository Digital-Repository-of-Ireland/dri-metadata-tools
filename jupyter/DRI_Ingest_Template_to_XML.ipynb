{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "RW25KHfd9XSL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Convert Digital Repository of Ireland (DRI) Ingest Template to XML files for batch ingest\n",
    "\n",
    "This Notebook will help you to transform your metadata from a spreadsheet in the format of the DRI Metadata template (avialable here https://doi.org/10.7486/DRI.qn603p95v-8) to a set of individual Dublin Core files in XML format ready for the use with the DRI Batch Ingest tool.\n",
    "\n",
    "The Notebook consists of three executable cells or steps:\n",
    "\n",
    "*   Initialisation\n",
    "*   Check and Clean the Metadata\n",
    "*   Process Metadata and create XML files\n",
    "\n",
    "Make sure that you run these cells in order. It is best to run them one by one, by selecting the cell you want to run and clicking the run button above. Once you have run the first cell, you will not have to re-run it unless you see an error or need to change some of the inputs. If you do re-run an earlier cell, e.g. to change the input filename, then you must run the subsequent cells again, in the correct order.\n",
    "\n",
    "The code in this Notebook was written by DRI Staff, but some AI features were used to suggest code. This is part of our ongoing work to explore legitimate uses for GenAI within the domain of archiving and repositories. You can find out more about how the DRI uses AI on our website https://dri.ie/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMi2A9z9c5Tw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initialisation\n",
    "Before running the initialisation cell below, you must upload your completed DRI Batch Metadata Template file in Excel format to storage available to the Notebook. You should also create an output folder to store the generated XML files.\n",
    "\n",
    "When you have completed this you should click on the run icon for the cell below which will read in your metadta file and set up some data that will be used in the rest of the Notebook.\n",
    "\n",
    "Bear in mind that it is important to run the cells in Jupyter Notebooks in order. If you try to run the checking or processing cells before you have run this initialisation cell, you will get errors or unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xPuEBHecwIB",
    "outputId": "be8ada4a-ff37-4b88-aaee-186cd800747b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must enter a valid filename for the file containing your metadata.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the file you have uploaded containing the cleaned metadata:  DRI_Metadata Template.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully found the input file \"DRI_Metadata Template.xlsx\"\n",
      "You must enter a valid folder name for the output folder, make sure you have created the folder first.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the output folder:  out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully found the output folder \"out\"\n",
      "If no errors are displayed here, you may now progress to execute the next code step.\n",
      "You may run the proceeding code steps as many times as you want without having to re-run this Initialisation step.\n",
      "You only need to re-run the Initialisation step if you got an error here, or if you want to change the input file or output folder\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "import re\n",
    "\n",
    "# Setup lists of valid fields which we will use for checking our metadata later\n",
    "dc_fields = [\n",
    "    'dc:identifier',\n",
    "    'dc:title',\n",
    "    'dcterms:alternative',\n",
    "    'dc:creator',\n",
    "    'dc:date',\n",
    "    'dcterms:created',\n",
    "    'dcterms:issued',\n",
    "    'dc:description',\n",
    "    'dc:rights',\n",
    "    'dc:type',\n",
    "    'dcterms:accessRights',\n",
    "    'dc:language',\n",
    "    'dc:contributor',\n",
    "    'dc:source',\n",
    "    'dc:coverage',\n",
    "    'dcterms:spatial',\n",
    "    'dcterms:temporal',\n",
    "    'dc:subject',\n",
    "    'dcterms:depicted',\n",
    "    'dc:relation',\n",
    "    'determs:isVersionOf',\n",
    "    'dcterms:hasVersion',\n",
    "    'dcterms:isPartOf',\n",
    "    'dcterms:hasPart',\n",
    "    'dcterms:isReferencedBy',\n",
    "    'dcterms:references',\n",
    "    'dcterms:isFormatOf',\n",
    "    'dcterms:hasFormat']\n",
    "\n",
    "marcrel_fields = [\"abr\",\"act\",\"adp\",\"rcp\",\"anl\",\"anm\",\"ann\",\"anc\",\"apl\",\"ape\",\n",
    "                  \"app\",\"arc\",\"arr\",\"acp\",\"adi\",\"art\",\"ill\",\"ard\",\"asg\",\"asn\",\n",
    "                  \"fmo\",\"att\",\"auc\",\"aue\",\"aup\",\"aut\",\"aqt\",\"aud\",\"ato\",\"ant\",\n",
    "                  \"bnd\",\"bdd\",\"blw\",\"bka\",\"bkd\",\"bkp\",\"bjd\",\"bpd\",\"bsl\",\"brl\",\n",
    "                  \"brd\",\"cll\",\"cop\",\"ctg\",\"cas\",\"cad\",\"cns\",\"chr\",\"cng\",\"cli\",\n",
    "                  \"cor\",\"col\",\"clt\",\"clr\",\"cmm\",\"cwt\",\"com\",\"cpl\",\"cpt\",\"cpe\",\n",
    "                  \"cmp\",\"cmt\",\"ccp\",\"cnd\",\"con\",\"csl\",\"csp\",\"cos\",\"cot\",\"coe\",\n",
    "                  \"cts\",\"ctt\",\"cte\",\"ctr\",\"ctb\",\"cpc\",\"cph\",\"crr\",\"crp\",\"cst\",\n",
    "                  \"cou\",\"crt\",\"cov\",\"cre\",\"cur\",\"dnc\",\"dtc\",\"dtm\",\"dte\",\"dto\",\n",
    "                  \"dfd\",\"dft\",\"dfe\",\"dgc\",\"dgg\",\"dgs\",\"dln\",\"dpc\",\"dpt\",\"dsr\",\n",
    "                  \"drt\",\"dis\",\"dbp\",\"dst\",\"djo\",\"dnr\",\"drm\",\"dbd\",\"dub\",\"edt\",\n",
    "                  \"edc\",\"edm\",\"edd\",\"elg\",\"elt\",\"enj\",\"eng\",\"egr\",\"etr\",\"evp\",\n",
    "                  \"exp\",\"fac\",\"fld\",\"fmd\",\"fds\",\"flm\",\"fmp\",\"fmk\",\"fpy\",\"frg\",\n",
    "                  \"fmo\",\"fon\",\"fnd\",\"gdv\",\"gis\",\"hnr\",\"hst\",\"his\",\"ilu\",\"ill\",\n",
    "                  \"ink\",\"ins\",\"itr\",\"ive\",\"ivr\",\"inv\",\"isb\",\"jud\",\"jug\",\"lbr\",\n",
    "                  \"ldr\",\"lsa\",\"led\",\"len\",\"ltr\",\"lil\",\"lit\",\"lie\",\"lel\",\"let\",\n",
    "                  \"lee\",\"lbt\",\"lse\",\"lso\",\"lgd\",\"ltg\",\"lyr\",\"mka\",\"mfp\",\"mfr\",\n",
    "                  \"mrb\",\"mrk\",\"med\",\"mdc\",\"mte\",\"mtk\",\"mxe\",\"mod\",\"mon\",\"mcp\",\n",
    "                  \"mup\",\"msd\",\"mus\",\"nrt\",\"nan\",\"onp\",\"osp\",\"opn\",\"orm\",\"org\",\n",
    "                  \"oth\",\"own\",\"pan\",\"ppm\",\"pta\",\"pth\",\"pat\",\"pnc\",\"prf\",\"prf\",\n",
    "                  \"pma\",\"pht\",\"pad\",\"ptf\",\"ptt\",\"pte\",\"plt\",\"pra\",\"pre\",\"prt\",\n",
    "                  \"pop\",\"prm\",\"prc\",\"pro\",\"prn\",\"prs\",\"pmn\",\"prd\",\"prp\",\"prg\",\n",
    "                  \"pdr\",\"pfr\",\"crr\",\"prv\",\"pbl\",\"pup\",\"pbl\",\"pbd\",\"ppt\",\"rdd\",\n",
    "                  \"rpc\",\"rap\",\"rce\",\"rcd\",\"red\",\"rxa\",\"ren\",\"rpt\",\"rps\",\"rth\",\n",
    "                  \"rtm\",\"res\",\"rsp\",\"rst\",\"rse\",\"rpy\",\"rsg\",\"rsr\",\"rev\",\"rbr\",\n",
    "                  \"sce\",\"sad\",\"aus\",\"scr\",\"fac\",\"scl\",\"spy\",\"sec\",\"sll\",\"std\",\n",
    "                  \"stg\",\"sgn\",\"ins\",\"sng\",\"swd\",\"sds\",\"sde\",\"spk\",\"sfx\",\"spn\",\n",
    "                  \"sgd\",\"stm\",\"stn\",\"str\",\"stl\",\"sht\",\"srv\",\"tch\",\"tad\",\"tcd\",\n",
    "                  \"tld\",\"tlg\",\"tlh\",\"tlp\",\"tau\",\"ths\",\"trc\",\"fac\",\"trl\",\"tyd\",\n",
    "                  \"tyg\",\"bkd\",\"uvp\",\"vdg\",\"vfx\",\"vac\",\"wit\",\"wde\",\"wdc\",\"wam\",\n",
    "                  \"wac\",\"wal\",\"wat\",\"waw\",\"wfs\",\"wfw\",\"wft\",\"win\",\"wpr\",\"wst\",\n",
    "                  \"wts\"]\n",
    "\n",
    "xml_header = '<qualifieddc xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:marcrel=\"http://www.loc.gov/marc.relators/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.loc.gov/marc.relators/ http://imlsdcc2.grainger.illinois.edu/registry/marcrel.xsd\" xsi:noNamespaceSchemaLocation=\"http://dublincore.org/schemas/xmls/qdc/2008/02/11/qualifieddc.xsd\">'\n",
    "xml_footer = '</qualifieddc>'\n",
    "\n",
    "# Get the filename to read and the output folder\n",
    "filename = \"\"\n",
    "while True:\n",
    "  if not path.isfile(filename):\n",
    "    print('You must enter a valid filename for the file containing your metadata.')\n",
    "  else:\n",
    "    print(f'Successfully found the input file \"{filename}\"')\n",
    "    break\n",
    "  filename = input('Please enter the name of the file you have uploaded containing the cleaned metadata: ')\n",
    "\n",
    "outputdir = \"\"\n",
    "while True:\n",
    "  if not path.isdir(outputdir):\n",
    "    print('You must enter a valid folder name for the output folder, make sure you have created the folder first.')\n",
    "  else:\n",
    "    print(f'Successfully found the output folder \"{outputdir}\"')\n",
    "    break\n",
    "  outputdir = input('Please enter the name of the output folder: ')\n",
    "\n",
    "print('If no errors are displayed here, you may now progress to execute the next code step.')\n",
    "print('You may run the proceeding code steps as many times as you want without having to re-run this Initialisation step.')\n",
    "print('You only need to re-run the Initialisation step if you see an error here, or if you want to change the input file or output folder.')\n",
    "    \n",
    "def lookup_case_insensitive(value, choices):\n",
    "    \"\"\"Return the matching value from choices with original case, or None if not found.\"\"\"\n",
    "    value_cf = value.casefold()\n",
    "    lookup = {c.casefold(): c for c in choices}\n",
    "    return lookup.get(value_cf)\n",
    "\n",
    "class CaseInsensitiveLookupManager:\n",
    "    def __init__(self):\n",
    "        self.lookups = {}\n",
    "\n",
    "    def register(self, name, choices):\n",
    "        \"\"\"Register a lookup set by name.\"\"\"\n",
    "        self.lookups[name] = {c.casefold(): c for c in choices}\n",
    "\n",
    "    def get(self, name, value):\n",
    "        \"\"\"Case-insensitive lookup in the named set.\"\"\"\n",
    "        return self.lookups.get(name, {}).get(value.casefold())\n",
    "\n",
    "    def find_in(self, names, value):\n",
    "        \"\"\"\n",
    "        Search for value in multiple sets in order.\n",
    "        Returns (set_name, match) or (None, None) if not found.\n",
    "        \"\"\"\n",
    "        value_cf = value.casefold()\n",
    "        for name in names:\n",
    "            match = self.lookups.get(name, {}).get(value_cf)\n",
    "            if match is not None:\n",
    "                return name, match\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "644FPmHkc_ig"
   },
   "source": [
    "## Check and Clean the Metadata\n",
    "The following cell will perform some checks on your metadata to make sure that it can be converted to Dublin Core XML files.\n",
    "\n",
    "1. First it will discard any empty columns, necessary as there will likely be columns in the metadata template that are not relevant for your data. We don't want to include these as empty Dublin Core elements in our xml files.\n",
    "\n",
    "2. Next it will check that all of the column headers match a valid Dublin Core element. You may have added additional columns to handle multiple values, e.g. for multiple Subjects you may have dc:Subject, dc:Subject2, dc:Subject3, etc. The Notebook will ask you to clarify the metadata mapping for any columns where this is unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkiUWxJM28X_",
    "outputId": "35f29977-414f-4305-b7d3-5d5e320d2ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field \"dc:Subject 2\" is not a valid Dublin Core field.\n",
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column: dc:subject\n",
      "Field \"dc:Subject 3\" is not a valid Dublin Core field.\n",
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column: dc:subject\n",
      "Field \"marcrel:***\" is not a valid MARC Relator code.\n",
      "Please specify the field (in the format marcrel:xxx) for mapping. Hit enter to ignore this column: \n",
      "Dropping column marcrel:***\n"
     ]
    }
   ],
   "source": [
    "# Read in the metadata file\n",
    "df = pd.read_excel(filename, 1)\n",
    "\n",
    "# drop any unused columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "drop_fields = []\n",
    "mappings = {}\n",
    "\n",
    "marcrel_pattern = re.compile('^marcrel:.*', re.IGNORECASE)\n",
    "\n",
    "lookup_manager = CaseInsensitiveLookupManager()\n",
    "lookup_manager.register(\"dc\", dc_fields)\n",
    "lookup_manager.register(\"marcrel\", marcrel_fields)\n",
    "\n",
    "for field in df.columns:\n",
    "    field_cf = field.casefold()\n",
    "\n",
    "    if field_cf == \"filename\":\n",
    "        continue\n",
    "\n",
    "    if marcrel_pattern.match(field):\n",
    "        ns, code = field.split(\":\")\n",
    "        _, match = lookup_manager.find_in([\"marcrel\"], code)\n",
    "        if not match:\n",
    "            print(f'Field \"{field}\" is not a valid MARC Relator code.')\n",
    "            tmp = input(\n",
    "                f'Please specify the field (in the format marcrel:xxx) for mapping. '\n",
    "                f'Hit enter to ignore this column: '\n",
    "            )\n",
    "            if tmp == \"\":\n",
    "                print(f'Dropping column {field}')\n",
    "                drop_fields.append(field)\n",
    "            else:\n",
    "                mappings[field] = tmp\n",
    "        else:\n",
    "            mappings[field] = \"marcrel:\"+match\n",
    "\n",
    "    else:\n",
    "        _, match = lookup_manager.find_in([\"dc\"], field)\n",
    "        if not match:\n",
    "            print(f'Field \"{field}\" is not a valid Dublin Core field.')\n",
    "            tmp = input(\n",
    "                f'Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. '\n",
    "                f'Hit enter to ignore this column: '\n",
    "            )\n",
    "            if tmp == \"\":\n",
    "                print(f'Dropping column {field}')\n",
    "                drop_fields.append(field)\n",
    "            else:\n",
    "                mappings[field] = tmp\n",
    "        else:\n",
    "            mappings[field] = match\n",
    "\n",
    "df = df.drop(drop_fields, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRRotjlvFuHQ"
   },
   "source": [
    "## Process Metadata and create XML files\n",
    "This next cell will iterate through all rows in your metadata spreadsheet, converting the cell values to xml and write these out to the output file which will be named for your Filename cell. A zip file metadata.zip, and a tar archive metadata.tar.gz, containing of your output folder will also be created. These can then be downloaded to your local machine and extracted, before ingesting into DRI or another Repository or application that supports Dublin Core metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1irCxJhfFjaq",
    "outputId": "6d88b11d-569b-4e6e-f236-9eed8d151c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: out// (stored 0%)\n",
      "  adding: out//file2.xml (deflated 54%)\n",
      "  adding: out//file1.xml (deflated 54%)\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "  xmlfile = open(f'{outputdir}/{row[\"Filename\"]}.xml', 'w')\n",
    "  xmlfile.write(xml_header)\n",
    "  for field in df.columns:\n",
    "    if field == \"Filename\":\n",
    "      continue\n",
    "    elif pd.isna(row[field]):\n",
    "      continue\n",
    "    else:\n",
    "      tmp = f'<{mappings[field]}>{row[field]}</{mappings[field]}>\\n'\n",
    "      xmlfile.write(tmp)\n",
    "  xmlfile.write(xml_footer)\n",
    "  xmlfile.close()\n",
    "\n",
    "!zip -r metadata.zip $outputdir\n",
    "!tar -czf metadata.tar.gz $outputdir\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
