{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "RW25KHfd9XSL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Convert Digital Repository of Ireland (DRI) Ingest Template to XML files for batch ingest\n",
    "\n",
    "This Notebook will help you to transform your metadata from a spreadsheet in the format of the DRI Metadata template (avialable here https://doi.org/10.7486/DRI.qn603p95v-8) to a set of individual Dublin Core files in XML format ready for the use with the DRI Batch Ingest tool.\n",
    "\n",
    "The Notebook consists of three executable cells or steps:\n",
    "\n",
    "*   Initialisation\n",
    "*   Check and Clean the Metadata\n",
    "*   Process Metadata and create XML files\n",
    "\n",
    "Make sure that you run these cells in order. It is best to run them one by one, by selecting the cell you want to run and clicking the run button above. Once you have run the first cell, you will not have to re-run it unless you see an error or need to change some of the inputs. If you do re-run an earlier cell, e.g. to change the input filename, then you must run the subsequent cells again, in the correct order.\n",
    "\n",
    "The code in this Notebook was written by DRI Staff, but some AI features were used to suggest code. This is part of our ongoing work to explore legitimate uses for GenAI within the domain of archiving and repositories. You can find out more about how the DRI uses AI on our website https://dri.ie/.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMi2A9z9c5Tw"
   },
   "source": [
    "## Initialisation\n",
    "Before running the initialisation cell below, you must upload your completed DRI Batch Metadata Template file in Excel format to storage available to the Notebook. You should also create an output folder to store the generated XML files.\n",
    "\n",
    "When you have completed this you should click on the run icon for the cell below which will read in your metadta file and set up some data that will be used in the rest of the Notebook.\n",
    "\n",
    "Bear in mind that it is important to run the cells in Jupyter Notebooks in order. If you try to run the checking or processing cells before you have run this initialisation cell, you will get errors or unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xPuEBHecwIB",
    "outputId": "be8ada4a-ff37-4b88-aaee-186cd800747b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must enter a valid filename for the file containing your metadata.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the file you have uploaded containing the cleaned metadata:  DRI_Metadata Template_withdups.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully found the input file \"DRI_Metadata Template_withdups.xlsx\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the tab in the spreadsheet DRI_Metadata Template_withdups.xlsx which contains the metadata Template\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must enter a valid folder name for the output folder, make sure you have created the folder first.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the output folder:  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully found the output folder \"output\"\n",
      "If no errors are displayed here, you may now progress to execute the next code step.\n",
      "You may run the proceeding code steps as many times as you want without having to re-run this Initialisation step.\n",
      "You only need to re-run the Initialisation step if you see an error here, or if you want to change the input file or output folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "import re\n",
    "\n",
    "# Setup lists of valid fields which we will use for checking our metadata later\n",
    "dc_fields = [\n",
    "    'dc:identifier',\n",
    "    'dc:title',\n",
    "    'dcterms:alternative',\n",
    "    'dc:creator',\n",
    "    'dc:date',\n",
    "    'dcterms:created',\n",
    "    'dcterms:issued',\n",
    "    'dc:description',\n",
    "    'dc:rights',\n",
    "    'dc:type',\n",
    "    'dcterms:accessRights',\n",
    "    'dc:language',\n",
    "    'dc:contributor',\n",
    "    'dc:source',\n",
    "    'dc:coverage',\n",
    "    'dcterms:spatial',\n",
    "    'dcterms:temporal',\n",
    "    'dc:subject',\n",
    "    'dcterms:depicted',\n",
    "    'dc:relation',\n",
    "    'determs:isVersionOf',\n",
    "    'dcterms:hasVersion',\n",
    "    'dcterms:isPartOf',\n",
    "    'dcterms:hasPart',\n",
    "    'dcterms:isReferencedBy',\n",
    "    'dcterms:references',\n",
    "    'dcterms:isFormatOf',\n",
    "    'dcterms:hasFormat']\n",
    "\n",
    "marcrel_fields = [\"abr\",\"act\",\"adp\",\"rcp\",\"anl\",\"anm\",\"ann\",\"anc\",\"apl\",\"ape\",\n",
    "                  \"app\",\"arc\",\"arr\",\"acp\",\"adi\",\"art\",\"ill\",\"ard\",\"asg\",\"asn\",\n",
    "                  \"fmo\",\"att\",\"auc\",\"aue\",\"aup\",\"aut\",\"aqt\",\"aud\",\"ato\",\"ant\",\n",
    "                  \"bnd\",\"bdd\",\"blw\",\"bka\",\"bkd\",\"bkp\",\"bjd\",\"bpd\",\"bsl\",\"brl\",\n",
    "                  \"brd\",\"cll\",\"cop\",\"ctg\",\"cas\",\"cad\",\"cns\",\"chr\",\"cng\",\"cli\",\n",
    "                  \"cor\",\"col\",\"clt\",\"clr\",\"cmm\",\"cwt\",\"com\",\"cpl\",\"cpt\",\"cpe\",\n",
    "                  \"cmp\",\"cmt\",\"ccp\",\"cnd\",\"con\",\"csl\",\"csp\",\"cos\",\"cot\",\"coe\",\n",
    "                  \"cts\",\"ctt\",\"cte\",\"ctr\",\"ctb\",\"cpc\",\"cph\",\"crr\",\"crp\",\"cst\",\n",
    "                  \"cou\",\"crt\",\"cov\",\"cre\",\"cur\",\"dnc\",\"dtc\",\"dtm\",\"dte\",\"dto\",\n",
    "                  \"dfd\",\"dft\",\"dfe\",\"dgc\",\"dgg\",\"dgs\",\"dln\",\"dpc\",\"dpt\",\"dsr\",\n",
    "                  \"drt\",\"dis\",\"dbp\",\"dst\",\"djo\",\"dnr\",\"drm\",\"dbd\",\"dub\",\"edt\",\n",
    "                  \"edc\",\"edm\",\"edd\",\"elg\",\"elt\",\"enj\",\"eng\",\"egr\",\"etr\",\"evp\",\n",
    "                  \"exp\",\"fac\",\"fld\",\"fmd\",\"fds\",\"flm\",\"fmp\",\"fmk\",\"fpy\",\"frg\",\n",
    "                  \"fmo\",\"fon\",\"fnd\",\"gdv\",\"gis\",\"hnr\",\"hst\",\"his\",\"ilu\",\"ill\",\n",
    "                  \"ink\",\"ins\",\"itr\",\"ive\",\"ivr\",\"inv\",\"isb\",\"jud\",\"jug\",\"lbr\",\n",
    "                  \"ldr\",\"lsa\",\"led\",\"len\",\"ltr\",\"lil\",\"lit\",\"lie\",\"lel\",\"let\",\n",
    "                  \"lee\",\"lbt\",\"lse\",\"lso\",\"lgd\",\"ltg\",\"lyr\",\"mka\",\"mfp\",\"mfr\",\n",
    "                  \"mrb\",\"mrk\",\"med\",\"mdc\",\"mte\",\"mtk\",\"mxe\",\"mod\",\"mon\",\"mcp\",\n",
    "                  \"mup\",\"msd\",\"mus\",\"nrt\",\"nan\",\"onp\",\"osp\",\"opn\",\"orm\",\"org\",\n",
    "                  \"oth\",\"own\",\"pan\",\"ppm\",\"pta\",\"pth\",\"pat\",\"pnc\",\"prf\",\"prf\",\n",
    "                  \"pma\",\"pht\",\"pad\",\"ptf\",\"ptt\",\"pte\",\"plt\",\"pra\",\"pre\",\"prt\",\n",
    "                  \"pop\",\"prm\",\"prc\",\"pro\",\"prn\",\"prs\",\"pmn\",\"prd\",\"prp\",\"prg\",\n",
    "                  \"pdr\",\"pfr\",\"crr\",\"prv\",\"pbl\",\"pup\",\"pbl\",\"pbd\",\"ppt\",\"rdd\",\n",
    "                  \"rpc\",\"rap\",\"rce\",\"rcd\",\"red\",\"rxa\",\"ren\",\"rpt\",\"rps\",\"rth\",\n",
    "                  \"rtm\",\"res\",\"rsp\",\"rst\",\"rse\",\"rpy\",\"rsg\",\"rsr\",\"rev\",\"rbr\",\n",
    "                  \"sce\",\"sad\",\"aus\",\"scr\",\"fac\",\"scl\",\"spy\",\"sec\",\"sll\",\"std\",\n",
    "                  \"stg\",\"sgn\",\"ins\",\"sng\",\"swd\",\"sds\",\"sde\",\"spk\",\"sfx\",\"spn\",\n",
    "                  \"sgd\",\"stm\",\"stn\",\"str\",\"stl\",\"sht\",\"srv\",\"tch\",\"tad\",\"tcd\",\n",
    "                  \"tld\",\"tlg\",\"tlh\",\"tlp\",\"tau\",\"ths\",\"trc\",\"fac\",\"trl\",\"tyd\",\n",
    "                  \"tyg\",\"bkd\",\"uvp\",\"vdg\",\"vfx\",\"vac\",\"wit\",\"wde\",\"wdc\",\"wam\",\n",
    "                  \"wac\",\"wal\",\"wat\",\"waw\",\"wfs\",\"wfw\",\"wft\",\"win\",\"wpr\",\"wst\",\n",
    "                  \"wts\"]\n",
    "\n",
    "xml_header = '<qualifieddc xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:marcrel=\"http://www.loc.gov/marc.relators/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.loc.gov/marc.relators/ http://imlsdcc2.grainger.illinois.edu/registry/marcrel.xsd\" xsi:noNamespaceSchemaLocation=\"http://dublincore.org/schemas/xmls/qdc/2008/02/11/qualifieddc.xsd\">'\n",
    "xml_footer = '</qualifieddc>'\n",
    "\n",
    "dri_mandatory_fields = ['dc:title',\n",
    "    'dc:creator',\n",
    "    'dc:date',\n",
    "    'dcterms:created',\n",
    "    'dcterms:issued',\n",
    "    'dc:description',\n",
    "    'dc:rights',\n",
    "    'dc:type']\n",
    "\n",
    "# Get the filename to read and the output folder\n",
    "filename = \"\"\n",
    "while True:\n",
    "  if not path.isfile(filename):\n",
    "    print('You must enter a valid filename for the file containing your metadata.')\n",
    "  else:\n",
    "    print(f'Successfully found the input file \"{filename}\"')\n",
    "    break\n",
    "  filename = input('Please enter the name of the file you have uploaded containing the cleaned metadata: ')\n",
    "\n",
    "tab = input(f'Please enter the name of the tab in the spreadsheet {filename} which contains the metadata')\n",
    "\n",
    "outputdir = \"\"\n",
    "while True:\n",
    "  if not path.isdir(outputdir):\n",
    "    print('You must enter a valid folder name for the output folder, make sure you have created the folder first.')\n",
    "  else:\n",
    "    print(f'Successfully found the output folder \"{outputdir}\"')\n",
    "    break\n",
    "  outputdir = input('Please enter the name of the output folder: ')\n",
    "\n",
    "print('If no errors are displayed here, you may now progress to execute the next code step.')\n",
    "print('You may run the proceeding code steps as many times as you want without having to re-run this Initialisation step.')\n",
    "print('You only need to re-run the Initialisation step if you see an error here, or if you want to change the input file or output folder.')\n",
    "    \n",
    "def lookup_case_insensitive(value, choices):\n",
    "    \"\"\"Return the matching value from choices with original case, or None if not found.\"\"\"\n",
    "    value_cf = value.casefold()\n",
    "    lookup = {c.casefold(): c for c in choices}\n",
    "    return lookup.get(value_cf)\n",
    "\n",
    "class CaseInsensitiveLookupManager:\n",
    "    def __init__(self):\n",
    "        self.lookups = {}\n",
    "\n",
    "    def register(self, name, choices):\n",
    "        \"\"\"Register a lookup set by name.\"\"\"\n",
    "        self.lookups[name] = {c.casefold(): c for c in choices}\n",
    "\n",
    "    def get(self, name, value):\n",
    "        \"\"\"Case-insensitive lookup in the named set.\"\"\"\n",
    "        return self.lookups.get(name, {}).get(value.casefold())\n",
    "\n",
    "    def find_in(self, names, value):\n",
    "        \"\"\"\n",
    "        Search for value in multiple sets in order.\n",
    "        Returns (set_name, match) or (None, None) if not found.\n",
    "        \"\"\"\n",
    "        value_cf = value.casefold()\n",
    "        for name in names:\n",
    "            match = self.lookups.get(name, {}).get(value_cf)\n",
    "            if match is not None:\n",
    "                return name, match\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "644FPmHkc_ig"
   },
   "source": [
    "## Check and Clean the Metadata\n",
    "The following cell will perform some checks on your metadata to make sure that it can be converted to Dublin Core XML files.\n",
    "\n",
    "1. First it will discard any empty columns, necessary as there will likely be columns in the metadata template that are not relevant for your data. We don't want to include these as empty Dublin Core elements in our xml files.\n",
    "\n",
    "2. Next it will check that all of the column headers match a valid Dublin Core element. You may have added additional columns to handle multiple values, e.g. for multiple Subjects you may have dc:Subject, dc:Subject2, dc:Subject3, etc. The Notebook will ask you to clarify the metadata mapping for any columns where this is unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wkiUWxJM28X_",
    "outputId": "35f29977-414f-4305-b7d3-5d5e320d2ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field \"dc:Subject.1\" is not a valid Dublin Core field.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column:  dc:subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dublin Core input. The field dc:Subject.1 will be mapped to dc:subject in the Dublin Core output file\n",
      "Field \"potato\" is not a valid Dublin Core field.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column:  dc:subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dublin Core input. The field potato will be mapped to dc:subject in the Dublin Core output file\n",
      "Field \"potato.1\" is not a valid Dublin Core field.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column:  dc:subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dublin Core input. The field potato.1 will be mapped to dc:subject in the Dublin Core output file\n",
      "Field \"dc:Subject 2\" is not a valid Dublin Core field.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column:  dc:subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dublin Core input. The field dc:Subject 2 will be mapped to dc:subject in the Dublin Core output file\n",
      "Field \"dc:Subject 3\" is not a valid Dublin Core field.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. Hit enter to ignore this column:  dc:subject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Dublin Core input. The field dc:Subject 3 will be mapped to dc:subject in the Dublin Core output file\n",
      "Field \"marcrel:***\" is not a valid MARC Relator code.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please specify the field (in the format marcrel:xxx) for mapping. Hit enter to ignore this column:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column marcrel:***\n",
      "Finished running the second step.\n",
      "If you do not see any errors here, you can safely proceed to the third step.\n"
     ]
    }
   ],
   "source": [
    "# Read in the metadata file\n",
    "try:\n",
    "    df = pd.read_excel(filename, tab)\n",
    "except Exception as e:\n",
    "    print('Failed to read the metadata file. '\n",
    "          'This may be because the first step has not been run or encountered an error. '\n",
    "          'Alternatively, you may have given the wrong name for the tab containing your metadata. '\n",
    "          'Please run the first step again.')\n",
    "    print(e)\n",
    "\n",
    "# drop any unused columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "drop_fields = []\n",
    "mappings = {}\n",
    "\n",
    "marcrel_pattern = re.compile('^marcrel:.*', re.IGNORECASE)\n",
    "\n",
    "lookup_manager = CaseInsensitiveLookupManager()\n",
    "lookup_manager.register(\"dc\", dc_fields)\n",
    "lookup_manager.register(\"marcrel\", marcrel_fields)\n",
    "\n",
    "for field in df.columns:\n",
    "    field_cf = field.casefold()\n",
    "\n",
    "    if field_cf == \"filename\":\n",
    "        continue\n",
    "\n",
    "    if marcrel_pattern.match(field):\n",
    "        ns1, code1 = field.split(\":\")\n",
    "        _, match1 = lookup_manager.find_in([\"marcrel\"], code1)\n",
    "        if not match1:\n",
    "            print(f'Field \"{field}\" is not a valid MARC Relator code.')\n",
    "            while True:\n",
    "              tmp = input(\n",
    "                f'Please specify the field (in the format marcrel:xxx) for mapping. '\n",
    "                f'Hit enter to ignore this column: '\n",
    "              )\n",
    "              if tmp == \"\":\n",
    "                print(f'Dropping column {field}')\n",
    "                drop_fields.append(field)\n",
    "                break\n",
    "              else:\n",
    "                ns2, code2 = tmp.split(\":\")\n",
    "                _, match2 = lookup_manager.find_in([\"marcrel\"], code2)\n",
    "                if not match2:\n",
    "                  print(f'The input \"{tmp}\" is not a valid MARC Relator code.')\n",
    "                else:\n",
    "                  print(f'Valid MARC Relator code input. The field {field} will be mapped to {tmp} in the Dublin Core output file')\n",
    "                  mappings[field] = tmp\n",
    "                  break\n",
    "        else:\n",
    "            mappings[field] = \"marcrel:\"+match1\n",
    "\n",
    "    else:\n",
    "        _, match1 = lookup_manager.find_in([\"dc\"], field)\n",
    "        if not match1:\n",
    "            print(f'Field \"{field}\" is not a valid Dublin Core field.')\n",
    "            while True:\n",
    "                tmp = input(\n",
    "                    f'Please specify the dc field (in the format dc:xxxxxx or dcterms:xxxxxx) for mapping. '\n",
    "                    f'Hit enter to ignore this column: '\n",
    "                )\n",
    "                if tmp == \"\":\n",
    "                    print(f'Dropping column {field}')\n",
    "                    drop_fields.append(field)\n",
    "                    break\n",
    "                else:\n",
    "                    _, match2 = lookup_manager.find_in([\"dc\"], tmp)\n",
    "                    if not match2:\n",
    "                        print(f'The input \"{tmp}\" is not a valid Dublin Core field.')\n",
    "                    else:\n",
    "                        print(f'Valid Dublin Core input. The field {field} will be mapped to {tmp} in the Dublin Core output file')\n",
    "                        mappings[field] = tmp\n",
    "                        break\n",
    "        else:\n",
    "            mappings[field] = match1\n",
    "\n",
    "df = df.drop(drop_fields, axis=1)\n",
    "\n",
    "print('Finished running the second step.')\n",
    "print('If you do not see any errors here, you can safely proceed to the third step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRRotjlvFuHQ"
   },
   "source": [
    "## Process Metadata and create XML files\n",
    "This next cell will iterate through all rows in your metadata spreadsheet.\n",
    "\n",
    "It will perform some additional checks as follows:\n",
    "\n",
    "1. It will look for cell values containing an ampersand (&) character. These may not be valid XML and need to be escaped (converted to the string \"&amp;\"). It will print a warning, but will not automatically convert these.\n",
    "2. It will check to see if all of the DRI Required fields are present. If not it will print a warning.\n",
    "\n",
    "Please note that both of the above checks will only result in a warning. They will not be corrected, or stop execution. Read the output from this step carefully to determine whether you need to make further changes to your metadata spreadsheet or to the output XML files.\n",
    "\n",
    "Finally it will convert the cell values to xml and write these out to the output file which will be named for your Filename cell. A zip file metadata.zip, and a tar archive metadata.tar.gz, containing of your output folder will also be created. These can then be downloaded to your local machine and extracted, before ingesting into DRI or another Repository or application that supports Dublin Core metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1irCxJhfFjaq",
    "outputId": "6d88b11d-569b-4e6e-f236-9eed8d151c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The file file1 does not have a dcterms:Created field. This is a mandatory field for DRI ingest, but this may not be a problem if you have one of the fields dc:date, dcterms:created or dcterms:issued\n",
      "WARNING: The following metadata entry in file file1 contains an & character and may not produce valid XML:\n",
      "potato2&\n",
      "WARNING: The file file2 does not have a dcterms:Issued field. This is a mandatory field for DRI ingest, but this may not be a problem if you have one of the fields dc:date, dcterms:created or dcterms:issued\n",
      "WARNING: A row without a \"Filename\" has been found. This row cannot be written to an XML file. Please check your metadata Spreadsheet and correct if required.\n",
      "WARNING: The file nan does not have a dc:Title field. This is a mandatory field for DRI ingest.\n",
      "WARNING: The file nan does not have a dcterms:Created field. This is a mandatory field for DRI ingest, but this may not be a problem if you have one of the fields dc:date, dcterms:created or dcterms:issued\n",
      "WARNING: The file nan does not have a dcterms:Issued field. This is a mandatory field for DRI ingest, but this may not be a problem if you have one of the fields dc:date, dcterms:created or dcterms:issued\n",
      "WARNING: The file nan does not have a dc:Description field. This is a mandatory field for DRI ingest.\n",
      "WARNING: The file nan does not have a dc:Rights field. This is a mandatory field for DRI ingest.\n",
      "WARNING: The file nan does not have a dc:Type field. This is a mandatory field for DRI ingest.\n",
      "/bin/bash: line 1: zip: command not found\n",
      "Finished running the final step.\n",
      "If you did not see any errors for any of the steps, then your output files should now be available in the output folder\n",
      "You should also see a zip file and/or tar.gz archive containing the output folder\n",
      "Please do not forget to download the zip/archive file before exiting your Jupyter Notebooks environment.\n"
     ]
    }
   ],
   "source": [
    "amp_pattern = re.compile(\".*&.*\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  if pd.isna(row[\"Filename\"]):\n",
    "      print('WARNING: A row without a \"Filename\" has been found. This row cannot be written to an XML file. '\n",
    "            'Please check your metadata Spreadsheet and correct if required.')\n",
    "  xmlfile = open(f'{outputdir}/{row[\"Filename\"]}.xml', 'w')\n",
    "  xmlfile.write(xml_header)\n",
    "        \n",
    "  for field in df.columns:\n",
    "    if field == \"Filename\":\n",
    "      continue\n",
    "    elif pd.isna(row[field]):\n",
    "      if (mappings[field] in dri_mandatory_fields) and (mappings[field] in ['dc:date','dcterms:created','dcterms:issued']):\n",
    "        print(f'WARNING: The file {row[\"Filename\"]} does not have a {field} field. '\n",
    "             'This is a mandatory field for DRI ingest, but this may not be a problem if you have one of the fields '\n",
    "             'dc:date, dcterms:created or dcterms:issued')\n",
    "      elif mappings[field] in dri_mandatory_fields:\n",
    "          print(f'WARNING: The file {row[\"Filename\"]} does not have a {field} field. '\n",
    "                'This is a mandatory field for DRI ingest.')\n",
    "      continue\n",
    "    else:\n",
    "      if amp_pattern.match(str(row[field])):\n",
    "        print(f'WARNING: The following metadata entry in file {row[\"Filename\"]} contains an & character and may not produce valid XML:')\n",
    "        print(row[field])\n",
    "      tmp = f'<{mappings[field]}>{row[field]}</{mappings[field]}>\\n'\n",
    "      xmlfile.write(tmp)\n",
    "  xmlfile.write(xml_footer)\n",
    "  xmlfile.close()\n",
    "\n",
    "!zip -r metadata.zip $outputdir\n",
    "!tar -czf metadata.tar.gz $outputdir\n",
    "\n",
    "print('Finished running the final step.')\n",
    "print(f'If you did not see any errors for any of the steps, then your output files should now be available in the {outputdir} folder')\n",
    "print('You should also see a zip file and/or tar.gz archive containing the output folder')\n",
    "print('Please do not forget to download the zip/archive file before exiting your Jupyter Notebooks environment.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
